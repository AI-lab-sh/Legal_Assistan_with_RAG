{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook contains the code to make a legal assistant using Rag and Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7fHWuszAK9k"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai weaviate-client pypdf langchain-community tiktoken chromadb langchain-google-genai ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 582,
     "status": "ok",
     "timestamp": 1753698112384,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "vmxPJ33yE3LZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Replace this with your actual API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"Gemini api key\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OpenAI api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2573,
     "status": "ok",
     "timestamp": 1753698117720,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "FOik6FkbuJKY",
    "outputId": "58e424b1-0d0f-4c26-8e01-fa7f7e999101"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "txt_path = \"/content/drive/MyDrive/sell_buy_rules.txt\"\n",
    "\n",
    "# Load the text file\n",
    "loader = TextLoader(txt_path, encoding=\"utf-8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fg3gr4JGyGzw"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"ØŒ\", \" \"]\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"âœ… Total chunks: {len(chunks)}\")\n",
    "print(f\"ğŸ“„ Sample chunk:\\n\\n{chunks[0].page_content[:500]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1753685978703,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "dwaFvBBmzNsH",
    "outputId": "828ffc39-89da-40f6-ba4a-858da989e356"
   },
   "outputs": [],
   "source": [
    "!echo $OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1411,
     "status": "ok",
     "timestamp": 1753698146101,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "y4HrrX7oy2Z0"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = Chroma.from_documents(documents=chunks, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1753698148719,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "H05Jzy8E0dTE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#llm = OpenAI(temperature=1.3, openai_api_key=openai_api_key)\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash\", temperature=0.7)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,  # Chat model like Gemini or ChatOpenAI\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UU4myUY4v6nt"
   },
   "outputs": [],
   "source": [
    "# Let's perform a similarity search in our vector store\n",
    "print(\"\\n--- Testing Similarity Search in Vector Store ---\")\n",
    "#test_query = \"Ø·Ù„Ø§Ù‚ Ø¨Ø§Ø¦Ù† Ø¯Ø± Ú†Ù‡ Ù…ÙˆØ§Ø±Ø¯ÛŒ Ø§Ø³ØªØŸ\"\n",
    "test_query = \"Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø¹ÛŒØ¨ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø¯Ø± Ù…Ø¨ÛŒØ¹ØŒ Ú†Ù‡ Ø­Ù‚ÙˆÙ‚ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³ØªØŸ\"\n",
    "print(f\"Searching for documents similar to: '{test_query}'\")\n",
    "\n",
    "\n",
    "# Perform a similarity search. 'k=2' retrieves the top 2 most similar chunks\n",
    "try:\n",
    "    similar_docs = vector_store.similarity_search(test_query, k = 2)\n",
    "    print(f\"\\nFound {len(similar_docs)} similar documents:\")\n",
    "\n",
    "    # Display snippets of the retrieved documents and their sources\n",
    "    for i, doc in enumerate(similar_docs):\n",
    "        print(f\"\\n--- Document {i+1} ---\")\n",
    "        # Displaying the first 700 chars for brevity\n",
    "        content_snippet = doc.page_content[:700].strip() + \"...\"\n",
    "        source = doc.metadata.get(\"source\", \"Unknown Source\")  # Get source from metadata\n",
    "        print(f\"Content Snippet: {content_snippet}\")\n",
    "        print(f\"Source: {source}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during similarity search: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dUoS0FA4iby"
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769,
     "referenced_widgets": [
      "da6ad1ce09614da9ba1476559e698db6",
      "3ddf62b58ac54ca3b6e7f4b5e78705e9",
      "16ed7d287d124fbbb60eb84bed7481c3",
      "7b85a39da98c41d19d3f1ffbc19b9923",
      "9b918889a3ed4d9b85b3d55546871ca6",
      "96956114a2224df98707422eba666713",
      "b9a35833a1934e319c350dccc4be0b99",
      "45a4453300f740069d019c6cf7932a06"
     ]
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1753698536641,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "k10ZY4tQ0iAm",
    "outputId": "64b34209-4c16-4e74-9652-eafdae19bb0c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def ask_question():\n",
    "    question_box = widgets.Textarea(\n",
    "        placeholder='Ù¾Ø±Ø³Ø´ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯...',\n",
    "        description='â“ Ø³ÙˆØ§Ù„:',\n",
    "        layout=widgets.Layout(width='100%', height='100px')\n",
    "    )\n",
    "\n",
    "    submit_button = widgets.Button(description=\"Ø§Ø±Ø³Ø§Ù„\", button_style='success')\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    def on_click_submit(b):\n",
    "        output_area.clear_output()\n",
    "        question = question_box.value.strip()\n",
    "\n",
    "        if question.lower() in ['Ø®Ø±ÙˆØ¬', 'exit', 'quit']:\n",
    "            with output_area:\n",
    "                display(Markdown(\"âœ… **Ù¾Ø§ÛŒØ§Ù† Ú¯ÙØªÚ¯Ùˆ.**\"))\n",
    "            return\n",
    "\n",
    "        # Run the RAG pipeline\n",
    "        result = qa_chain.invoke({\"query\": question})\n",
    "        answer = result['result']\n",
    "        sources = result['source_documents']\n",
    "\n",
    "        # Format the answer nicely in Markdown\n",
    "        markdown_response = f\"\"\"### âœ… Ù¾Ø§Ø³Ø®:\n",
    "{answer.strip()}\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“„ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø³ØªÙØ§Ø¯Ù‡â€ŒØ´Ø¯Ù‡:\n",
    "\"\"\" + '\\n'.join([f\"- {doc.metadata.get('source', 'Ø¨Ø®Ø´ Ø§Ø² Ø³Ù†Ø¯')}\" for doc in sources])\n",
    "\n",
    "        with output_area:\n",
    "            display(Markdown(markdown_response))\n",
    "\n",
    "        # Restart input loop\n",
    "        display(question_box, submit_button, output_area)\n",
    "\n",
    "    submit_button.on_click(on_click_submit)\n",
    "    display(question_box, submit_button, output_area)\n",
    "\n",
    "# Start\n",
    "ask_question()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "executionInfo": {
     "elapsed": 5037,
     "status": "ok",
     "timestamp": 1753698462455,
     "user": {
      "displayName": "shima khosravani",
      "userId": "16013126042930970123"
     },
     "user_tz": -210
    },
    "id": "c_u22VRHA39U",
    "outputId": "049068a0-a3b0-42e7-8e48-4dd5f36ef7fa"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"Gemini api key\"\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"models/gemini-1.5-flash\", temperature=0.7)\n",
    "response = llm.invoke(\"Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø¹ÛŒØ¨ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø¯Ø± Ù…Ø¨ÛŒØ¹ØŒ Ú†Ù‡ Ø­Ù‚ÙˆÙ‚ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø´ØªØ±ÛŒ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³ØªØŸ\")\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOAmUGV24QJL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOfHEj/tePMLdM3YuRZaqHJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
